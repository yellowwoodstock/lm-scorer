{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CUDA lm-scorer.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPBN2uloHqe4HkxRZOwxEPT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yellowwoodstock/lm-scorer/blob/master/gpu_lm_scorer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zEZRDHu04Jh"
      },
      "source": [
        "!python --version\n",
        "!pip --version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfFhJ4wr1SF6"
      },
      "source": [
        "!pip list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSeyLlc63bo7"
      },
      "source": [
        "!pip install -qq git+https://github.com/yellowwoodstock/lm-scorer.git\n",
        "!pip show lm-scorer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQD1vpTm3-2_"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNQOZN1e7dFw"
      },
      "source": [
        "!pip install -qq wandb\n",
        "import wandb\n",
        "wandb.init()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlIYTZVz4DE2"
      },
      "source": [
        "%%writefile sentences.txt\n",
        "I am going to run a marathon.\n",
        "I am go to run a marathon."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoPe1WYe4It2"
      },
      "source": [
        "# @markdown The LM model to use.\n",
        "MODEL = 'gpt2'  #@param [\"gpt2\", \"gpt2-medium\", \"gpt2-large\", \"gpt2-xl\", \"distilgpt2\"]\n",
        "# @markdown Reduction strategy used to compute the sentence score out of tokens' probabilities.\n",
        "REDUCE = 'prod'  #@param [\"prod\", \"mean\", \"gmean\", \"hmean\"]\n",
        "# @markdown CUDA device id to use (e.g. 0), a negative value disables CUDA accelleration.\n",
        "CUDA = 0  #@param {type: \"number\"}\n",
        "# @markdown Number of sentences to simultaneously feed through the model.\n",
        "BATCH_SIZE = 1  #@param {type: \"number\"}\n",
        "\n",
        "!lm-scorer -m $MODEL -r $REDUCE -b $BATCH_SIZE --cuda $CUDA -lp -t sentences.txt"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}